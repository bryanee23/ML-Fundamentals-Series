{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597200625128",
   "display_name": "Python 3.7.4 64-bit ('ML': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Support Vector Machine</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "### Learning Objective:\n",
    "- Use SVM (Support Vector Machines) to build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.\n",
    "\n",
    "<img src=\"images/SVM0.png\" style=\"width:260px;\"> \n",
    "\n",
    "\n",
    "### When to use:\n",
    "\n",
    "<img src=\"images/SVM6.png\" style=\"width:250px;\"> \n",
    "\n",
    "### NOTES:\n",
    "\n",
    "<img src=\"images/SVM1.png\" style=\"width:250px;\"> \n",
    "\n",
    "<img src=\"images/SVM2.png\" style=\"width:250px;\"> \n",
    "<img src=\"images/SVM5.png\" style=\"width:250px;\"> \n",
    "\n",
    "<img src=\"images/SVM4.png\" style=\"width:250px;\"> \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "#### Prepare Data\n",
    "- SVM works by mapping data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. \n",
    "\n",
    "#### Prepare Data\n",
    "- A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. \n",
    "\n",
    "#### Modeling\n",
    "- Following this, characteristics of new data can be used to predict the group to which a new record should belong.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Road Map\n",
    "\n",
    "- Visualizing\n",
    "> - overlay the malignant and benign data\n",
    "\n",
    "- Cleaning\n",
    "> - verify the datatypes of all the values\n",
    "> - remove any rows w/out integer values\n",
    "\n",
    "- Preparing\n",
    "> - convert all values into an np.array\n",
    "> - normalize data if values are vary in range\n",
    "> - split the training and testing sets\n",
    "\n",
    "- Modeling\n",
    "> - fit the training sets into the algorithm\n",
    "\n",
    "- Evaluating\n",
    "> - create confusion matrix\n",
    "> - compute F1 score of y_hat, y_test\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning:\n",
    "\n",
    "1. Check data types of each value\n",
    "- pd.dtypes\n",
    "\n",
    "2. Verify column values\n",
    "- df.columns\n",
    "\n",
    "3. Drop rows containing unwanted rows\n",
    "> From the docs\n",
    "\n",
    "> - pandas.to_numeric(arg, errors='raise', downcast=None)\n",
    "\n",
    "> - Convert argument to a numeric type.\n",
    "\n",
    "Parameters:\n",
    "> arg : scalar, list, tuple, 1-d array, or Series\n",
    "> - Argument to be converted.\n",
    "\n",
    "> - errors : {‘ignore’, ‘raise’, ‘coerce’}, default ‘raise’\n",
    "> - If ‘raise’, then invalid parsing will raise an exception.\n",
    "> - If ‘coerce’, then invalid parsing will be set as NaN.\n",
    "> - If ‘ignore’, then invalid parsing will return the input.\n",
    "\n",
    "4. convert object into integers\n",
    "> - df.column = df.column.asytpe('int')\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparing:\n",
    "\n",
    "\n",
    "select features\n",
    "> - sklearn.model_selection.train_test_split(*arrays, **options)\n",
    "\n",
    "split data\n",
    "> - sklearn.model_selection.train_test_split(*arrays, **options)\n",
    "> - options: test_size=0.2 (20% of data), random_state=4\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Modeling:\n",
    "\n",
    "\n",
    "1. fit the model into SVM algo\n",
    "> From the docs\n",
    "\n",
    "> - class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "> C-Support Vector Classification.\n",
    "> The implementation is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples. For large datasets consider using sklearn.svm.LinearSVC or sklearn.linear_model.SGDClassifier instead, possibly after a sklearn.kernel_approximation.Nystroem transformer.\n",
    "\n",
    "Parameters:\n",
    "> - kernel : {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    " \n",
    "> Specifies the kernel type to be used in the algorithm. It must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ or a callable. If none is given, ‘rbf’ will be used. If a callable is given it is used to pre-compute the kernel matrix from data matrices; that matrix should be an array of shape (n_samples, n_samples).\n",
    "\n",
    "Methods: \n",
    "\n",
    "> - fit(X, y) : Fit the SVM model according to the given training data.\n",
    "\n",
    "> - predict(X) : Perform classification on samples in X.\n",
    "\n",
    "> - score(X, y) : Return the mean accuracy on the given test data and labels.\n",
    "\n",
    "\n",
    "2. Predict outputs from x_test data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluation:\n",
    "\n",
    "1a. confusion matrix\n",
    "\n",
    "> From the docs\n",
    "\n",
    "> - sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
    "\n",
    "Parameters:\n",
    "\n",
    "> - label : sarray-like of shape (n_classes), default=None\n",
    "\n",
    "> List of labels to index the matrix. This may be used to reorder or select a subset of labels. If None is given, those that appear at least once in y_true or y_pred are used in sorted order.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "1b. classification report\n",
    "\n",
    "> From the docs\n",
    "\n",
    "> sklearn.metrics.classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "\n",
    "Parameters:\n",
    "\n",
    "> - y_true : 1d array-like, or label indicator array / sparse matrix\n",
    "Ground truth (correct) target values.\n",
    "\n",
    "> - y_pred : 1d array-like, or label indicator array / sparse matrix\n",
    "Estimated targets as returned by a classifier.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. F1 score\n",
    "\n",
    "> From the docs\n",
    "\n",
    "> - sklearn.metrics.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
    "\n",
    "> Compute the F1 score, also known as balanced F-score or F-measure\n",
    "\n",
    "> The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
    "\n",
    "> $ F1 = 2 * (precision * recall) / (precision + recall) $\n",
    "\n",
    "> In the multi-class and multi-label case, this is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "Parameters:\n",
    "> - average : string, [None, ‘binary’ (default), ‘micro’, ‘macro’, ‘samples’, ‘weighted’]\n",
    "This parameter is required for multiclass/multilabel targets. If None, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data:\n",
    "\n",
    "> - 'binary': Only report results for the class specified by pos_label. This is applicable only if targets (y_{true,pred}) are binary.\n",
    "\n",
    "> - 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "\n",
    "> - 'macro': Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "\n",
    "> - 'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
    "\n",
    "> - 'samples': Calculate metrics for each instance, and find their average (only meaningful for multilabel classification where this differs from accuracy_score).\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Confusion Matrix: \n [[85  5]\n [ 0 47]] \n\nClassification report: \n               precision    recall  f1-score   support\n\n           2       1.00      0.94      0.97        90\n           4       0.90      1.00      0.95        47\n\n   micro avg       0.96      0.96      0.96       137\n   macro avg       0.95      0.97      0.96       137\nweighted avg       0.97      0.96      0.96       137\n \n\nF1 Score of the alogrithm is 0.96390\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import preprocessing, model_selection, svm, metrics\n",
    "\n",
    "# Cleaning\n",
    "df = pd.read_csv('datasets/cell_samples.csv')\n",
    "drop_rows = pd.to_numeric(df['BareNuc'], errors='coerce').notnull()\n",
    "df = df[drop_rows]\n",
    "df['BareNuc'] = df['BareNuc'].astype('int')\n",
    "\n",
    "output = ['Class']\n",
    "features = ['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize','BareNuc', 'BlandChrom', 'NormNucl','Mit']\n",
    "\n",
    "x = df[features].values\n",
    "y = df[output].values\n",
    "\n",
    "# Preparing\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# modeling\n",
    "y_hat = svm.SVC(kernel='linear').fit(x_train, y_train).predict(x_test)\n",
    "\n",
    "# evaluation\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_hat, labels=[2,4])\n",
    "print('Confusion Matrix: \\n', confusion_matrix,'\\n')\n",
    "\n",
    "classification_report = metrics.classification_report(y_test, y_hat)\n",
    "print('Classification report: \\n %s' % classification_report, '\\n')\n",
    "\n",
    "f1_score = metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "print('F1 Score of the alogrithm is %.5f' % f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Disclaimer</h2>\n",
    "\n",
    "This script was orginally from Coursera's [IBM AI Engineering course](https://www.coursera.org/professional-certificates/ai-engineer), authored by <a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a> and was modifed to fit my needs. "
   ]
  }
 ]
}