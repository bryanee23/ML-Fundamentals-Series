{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598126271440",
   "display_name": "Python 3.7.4 64-bit ('ML': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Classifier Project\n",
    "\n",
    "The following algorithms were used to build prediction models:\n",
    "- k-Nearest Neighbour\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "\n",
    "The results is reported as the accuracy of each classifier, using the following metrics when these are applicable:\n",
    "- Jaccard index\n",
    "- F1-score\n",
    "- LogLoss\n",
    "\n",
    "Dataset Details:\n",
    "- 346 rows\n",
    "- 10 columns\n",
    "\n",
    "---\n",
    "\n",
    "[Code on IBM Watson Studio] (https://dataplatform.cloud.ibm.com/analytics/notebooks/v2/ee3cecd1-8813-4c59-90ad-fe4e431ef407/view?access_token=367cb53e15dad3acdc058045e4cd28f69709fc25521840024d515aacda57ea74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean\n",
    "- check data types\n",
    "- change dtypes astype\n",
    "- reorganize dataframe\n",
    "### Prep\n",
    "- select features\n",
    "- normalize data using standardScalar\n",
    "- split data train_and_test_split\n",
    "- preprocessing - fit_transform,label_encoder, standardScalar\n",
    "- model_selection - train_and_test_split\n",
    "\n",
    "### Model\n",
    "- linear_model - LinearRegression\n",
    "- cluster - KMeans\n",
    "- neighbors - KNeighborsClassifer\n",
    "- tree - DecisionTreeClassifier\n",
    "- SVM - SVC\n",
    "\n",
    "### Evaluate\n",
    "- metrics - r2_score, report, jaccard, f1_score, logloss\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing, model_selection, neighbors, metrics, tree, svm, linear_model\n",
    "\n",
    "df = pd.read_csv('loan_train.csv')\n",
    "\n",
    "# clean\n",
    "rearrange_cols = ['Principal', 'terms','age', 'education', 'Gender','loan_status']\n",
    "df = df[rearrange_cols]\n",
    "df_visual = df[rearrange_cols]\n",
    "\n",
    "# prep\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df['Gender'] = label_encoder.fit(['male', 'female']).transform(df['Gender'].values)\n",
    "df['education'] = label_encoder.fit(['High School or Below', 'college', 'Bechalor', 'Master or Above']).transform(df['education'].values)\n",
    "df['loan_status'] = label_encoder.fit_transform(df['loan_status'].values)\n",
    "\n",
    "features = ['Principal', 'terms','age', 'education', 'Gender']\n",
    "y = df['loan_status'].values\n",
    "x = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jaccard Score: 0.714\nF1 Score: 0.828\nLog Loss: 9.868\n\n Classification Report: KNN \n               precision    recall  f1-score   support\n\n           0       0.22      0.13      0.17        15\n           1       0.79      0.87      0.83        55\n\n   micro avg       0.71      0.71      0.71        70\n   macro avg       0.50      0.50      0.50        70\nweighted avg       0.67      0.71      0.69        70\n\n"
    }
   ],
   "source": [
    "# Prep - KNN\n",
    "x_KNN = preprocessing.StandardScaler().fit_transform(x)\n",
    "x_train_KNN, x_test_KNN, y_train_KNN, y_test_KNN = model_selection.train_test_split(x_KNN,y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Model - KNN\n",
    "k = math.log(df.shape[0])\n",
    "k = math.ceil(k)\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=k).fit(x_train_KNN,y_train_KNN)\n",
    "y_hat_KNN = KNN.predict(x_test_KNN)\n",
    "y_prob_KNN = KNN.predict_proba(x_test_KNN)\n",
    "\n",
    "# Evaluate - KNN\n",
    "jaccard_score_KNN = metrics.jaccard_similarity_score(y_test_KNN, y_hat_KNN)\n",
    "f1_score_KNN = metrics.f1_score(y_test_KNN, y_hat_KNN)\n",
    "class_report_KNN = metrics.classification_report(y_test_KNN, y_hat_KNN)\n",
    "\n",
    "print('Jaccard Score (KNN): %.03f' % jaccard_score_KNN)\n",
    "print('F1 Score (KNN): %.03f' % f1_score_KNN)\n",
    "print('\\n Classification Report: KNN \\n', class_report_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jaccard Score: 0.786\nF1 Score: 0.880\n\n Classification Report: KNN \n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        15\n           1       0.79      1.00      0.88        55\n\n   micro avg       0.79      0.79      0.79        70\n   macro avg       0.39      0.50      0.44        70\nweighted avg       0.62      0.79      0.69        70\n\n"
    }
   ],
   "source": [
    "# Prep - Decision Tree\n",
    "x_train_tree, x_test_tree, y_train_tree, y_test_tree = model_selection.train_test_split(x,y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Model - Decision Tree\n",
    "decision_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3).fit(x_train_tree, y_train_tree)\n",
    "y_hat_tree = decision_tree.predict(x_test_tree)\n",
    "y_prob_tree = decision_tree.predict_proba(x_test_tree)\n",
    "\n",
    "jaccard_score_tree = metrics.jaccard_similarity_score(y_test_tree, y_hat_tree)\n",
    "f1_score_tree = metrics.f1_score(y_test_tree, y_hat_tree)\n",
    "class_report_tree = metrics.classification_report(y_test_tree, y_hat_tree)\n",
    "log_loss_tree = metrics.log_loss(y_test_tree, y_prob_tree)\n",
    "\n",
    "print('Jaccard Score (Tree): %.03f' % jaccard_score_tree)\n",
    "print('F1 Score (Tree): %.03f' % f1_score_tree)\n",
    "print('\\n Classification Report: KNN \\n', class_report_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jaccard Score (SVM): 0.786\nF1 Score (SVM): 0.880\n\n Classification Report: SVM \n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        15\n           1       0.79      1.00      0.88        55\n\n   micro avg       0.79      0.79      0.79        70\n   macro avg       0.39      0.50      0.44        70\nweighted avg       0.62      0.79      0.69        70\n\n"
    }
   ],
   "source": [
    "# Prep - SVM\n",
    "x_SVM = preprocessing.StandardScaler().fit_transform(x)\n",
    "x_train_SVM, x_test_SVM, y_train_SVM, y_test_SVM = model_selection.train_test_split(x_SVM, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Model\n",
    "SVM = svm.SVC(kernel='linear').fit(x_train_SVM, y_train_SVM)\n",
    "y_hat_SVM = SVM.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "jaccard_score_SVM = metrics.jaccard_similarity_score(y_test_SVM, y_hat_SVM)\n",
    "class_report_SVM = metrics.classification_report(y_test_SVM, y_hat_SVM)\n",
    "f1_score_SVM = metrics.f1_score(y_test_SVM, y_hat_SVM)\n",
    "\n",
    "\n",
    "print('Jaccard Score (SVM): %.03f' % jaccard_score_SVM)\n",
    "print('F1 Score (SVM): %.03f' % f1_score_SVM)\n",
    "print('\\n Classification Report: SVM \\n', class_report_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jaccard Score: 0.786\nF1 Score: 0.880\nLog Loss: 0.556\n"
    }
   ],
   "source": [
    "# Prep - Logistic Regression\n",
    "x_LR = preprocessing.StandardScaler().fit_transform(x)\n",
    "x_train_LR, x_test_LR, y_train_LR, y_test_LR = model_selection.train_test_split(x, y, test_size=0.2, random_state=4)\n",
    "\n",
    "# Model\n",
    "log_reg = linear_model.LogisticRegression(C=0.01, solver='liblinear').fit(x_train_LR, y_train_LR)\n",
    "y_hat_LR = log_reg.predict(x_test_LR)\n",
    "y_prob_LR = log_reg.predict_proba(x_test_LR)\n",
    "\n",
    "# Evaluation\n",
    "f1_score_LR = metrics.f1_score(y_test_LR, y_hat_LR)\n",
    "jaccard_score_LR = metrics.jaccard_similarity_score(y_test_LR, y_hat_LR)\n",
    "log_loss_score_LR = metrics.log_loss(y_test_LR, y_prob_LR)\n",
    "\n",
    "print('Jaccard Score (LR): %.03f' % jaccard_score_LR)\n",
    "print('F1 Score (LR): %.03f' % f1_score_LR)\n",
    "print('Log Loss (LR): %.03f' % log_loss_score_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Jaccard Score (KNN): 0.71429\nJaccard Score (Tree): 0.78571\nJaccard Score (LR): 0.78571\nJaccard Score (SVM): 0.78571\nF1 Score (KNN): 0.82759\nF1 Score (Tree): 0.88000\nF1 Score (LR): 0.88000\nF1 Score (SVM): 0.88000\nLog Loss (LR): 0.55586\n\n Classification Report: KNN \n               precision    recall  f1-score   support\n\n           0       0.22      0.13      0.17        15\n           1       0.79      0.87      0.83        55\n\n   micro avg       0.71      0.71      0.71        70\n   macro avg       0.50      0.50      0.50        70\nweighted avg       0.67      0.71      0.69        70\n\n\n Classification Report: KNN \n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        15\n           1       0.79      1.00      0.88        55\n\n   micro avg       0.79      0.79      0.79        70\n   macro avg       0.39      0.50      0.44        70\nweighted avg       0.62      0.79      0.69        70\n\n\n Classification Report: SVM \n               precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00        15\n           1       0.79      1.00      0.88        55\n\n   micro avg       0.79      0.79      0.79        70\n   macro avg       0.39      0.50      0.44        70\nweighted avg       0.62      0.79      0.69        70\n\n"
    }
   ],
   "source": [
    "print('Jaccard Score (KNN): %.05f' % jaccard_score_KNN)\n",
    "print('Jaccard Score (Tree): %.05f' % jaccard_score_tree)\n",
    "print('Jaccard Score (LR): %.05f' % jaccard_score_LR)\n",
    "print('Jaccard Score (SVM): %.05f' % jaccard_score_SVM)\n",
    "\n",
    "\n",
    "print('F1 Score (KNN): %.05f' % f1_score_KNN)\n",
    "print('F1 Score (Tree): %.05f' % f1_score_tree)\n",
    "print('F1 Score (LR): %.05f' % f1_score_LR)\n",
    "print('F1 Score (SVM): %.05f' % f1_score_SVM)\n",
    "\n",
    "print('Log Loss (LR): %.05f' % log_loss_score_LR)\n",
    "\n",
    "print('\\n Classification Report: KNN \\n', class_report_KNN)\n",
    "print('\\n Classification Report: KNN \\n', class_report_tree)\n",
    "print('\\n Classification Report: SVM \\n', class_report_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}